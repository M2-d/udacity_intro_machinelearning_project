{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection by k_best_features\n",
      "\n",
      "10 best features in descending order: ['exercised_stock_options' 'total_stock_value' 'bonus' 'salary'\n",
      " 'deferred_income' 'poi_ratio' 'long_term_incentive' 'restricted_stock'\n",
      " 'total_payments' 'shared_receipt_with_poi']\n",
      "\n",
      "                   feature      score  percent_nan\n",
      "0  exercised_stock_options  24.815080         29.9\n",
      "1        total_stock_value  24.182899         13.2\n",
      "2                    bonus  20.792252         43.8\n",
      "3                   salary  18.289684         34.7\n",
      "4          deferred_income  11.458477         66.7\n",
      "5                poi_ratio  10.019415         40.3\n",
      "6      long_term_incentive   9.922186         54.9\n",
      "7         restricted_stock   9.212811         24.3\n",
      "8           total_payments   8.772778         14.6\n",
      "9  shared_receipt_with_poi   8.589421         40.3\n",
      "\n",
      "##############################################################################################\n",
      "best_a_clf\n",
      "\n",
      "Pipeline(steps=[('scale_features', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, n_components=None, whiten=False)), ('adaboost', Pipeline(steps=[('reduce_dim', PCA(copy=True, n_components=0.95, whiten=False)), ('adaboost', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=2,\n",
      "          n_estimators=5, random_state=None))]))])\n",
      "\tAccuracy: 0.88460\tPrecision: 0.62465\tRecall: 0.33700\tF1: 0.43780\tF2: 0.37119\n",
      "\tTotal predictions: 15000\tTrue positives:  674\tFalse positives:  405\tFalse negatives: 1326\tTrue negatives: 12595\n",
      "\n",
      "##############################################################################################\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import test_classifier, dump_classifier_and_data\n",
    "\n",
    "#additional imports\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import enron_tools\n",
    "import enron_evaluate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "import enron_evaluate\n",
    "\n",
    "sep = '##############################################################################################'\n",
    "sep2 = '++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++'\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )\n",
    "\n",
    "### create list of functions for use as argument to add_features function\n",
    "add_feature_function_list = [enron_tools.add_poi_to_ratio,enron_tools.add_poi_from_ratio,enron_tools.add_poi_interaction_ratio]\n",
    "\n",
    "## add features to data_dict\n",
    "enron_tools.add_features(add_feature_function_list,data_dict)\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "\n",
    "data_label = 'poi'\n",
    "features_list = enron_tools.get_features(data_dict)\n",
    "\n",
    "\n",
    "## email address does not help with prediction and causes exeception, remove\n",
    "features_list.remove('email_address')\n",
    "\n",
    "\n",
    "##remove the data_label so that it can be re-added as the first feature element\n",
    "features_list.remove('poi')\n",
    "\n",
    "##reassemble feaures with the data label as the first element\n",
    "features_list = [data_label] + features_list\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "\n",
    "outliers = ['TOTAL','THE TRAVEL AGENCY IN THE PARK']\n",
    "\n",
    "enron_tools.remove_outliers(data_dict, outliers)\n",
    "\n",
    "\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "### Continue Feature Selection and dimensionality reduction via get_k_best\n",
    "\n",
    "## get k (k represents number of features) best features\n",
    "k = 10\n",
    "k_best_features = enron_tools.get_k_best(data_dict,features_list,k)\n",
    "\n",
    "print sep\n",
    "\n",
    "# assemble feature list\n",
    "my_features_list = [data_label] + list(k_best_features.feature.values)\n",
    "\n",
    "\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "### extract features and labels for gridsearch optimization\n",
    "\n",
    "# data extraction using k_best features list\n",
    "data = featureFormat(my_dataset, my_features_list, sort_keys = True)\n",
    "\n",
    "tru, trn = targetFeatureSplit(data)\n",
    "\n",
    "## scale extracted features\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "trn = scaler.fit_transform(trn)\n",
    "\n",
    "\n",
    "# Set up cross validator (will be used for tuning all classifiers)\n",
    "cv = cross_validation.StratifiedShuffleSplit(tru,\n",
    "                                            n_iter = 10,\n",
    "                                             random_state = 42)\n",
    "\n",
    "## Final Adaboost Classifier\n",
    "\n",
    "# Adaboost Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "a_clf = AdaBoostClassifier()\n",
    "\n",
    "# set up estimator and pipeline, using PCA for feature selection\n",
    "estimators = [('reduce_dim', PCA()),('adaboost',a_clf)]\n",
    "aclf = Pipeline(estimators)\n",
    "\n",
    "# set up paramaters dictionary\n",
    "a_params = dict(reduce_dim__n_components=[perc_var],\n",
    "              adaboost__n_estimators=[5, 10, 30, 40, 50, 100, 150, 200],\n",
    "                  adaboost__learning_rate=[0.1, 0.5, 1, 1.5, 2, 2.5],\n",
    "                   adaboost__algorithm=('SAMME', 'SAMME.R'))\n",
    "\n",
    "# set up gridsearch\n",
    "a_grid_search = GridSearchCV(aclf, param_grid = a_params,\n",
    "                          scoring = 'f1', cv =cv)\n",
    "# pass data into into the gridsearch via fit\n",
    "a_grid_search.fit(trn,tru)\n",
    "\n",
    "best_aclf = a_grid_search.best_estimator_\n",
    "\n",
    "## Evaluate Tuned Adaboost Classifier\n",
    "\n",
    "\n",
    "best_a_pipe_scale = Pipeline(steps=[('scale_features',preprocessing.MinMaxScaler()),('pca',PCA(n_components=.95)),('adaboost',best_aclf)])\n",
    "\n",
    "\n",
    "print 'best_a_clf\\n'\n",
    "test_classifier(best_a_pipe,my_dataset,my_features_list)\n",
    "print sep\n",
    "\n",
    "### Dump classifier for use in final algorithm poi_id\n",
    "\n",
    "pickle.dump(best_a_pipe_scale, open('best_clf_pipe.pkl', \"w\") )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection by k_best_features\n",
      "\n",
      "10 best features in descending order: ['exercised_stock_options' 'total_stock_value' 'bonus' 'salary'\n",
      " 'deferred_income' 'poi_ratio' 'long_term_incentive' 'restricted_stock'\n",
      " 'total_payments' 'shared_receipt_with_poi']\n",
      "\n",
      "                   feature      score  percent_nan\n",
      "0  exercised_stock_options  24.815080         29.9\n",
      "1        total_stock_value  24.182899         13.2\n",
      "2                    bonus  20.792252         43.8\n",
      "3                   salary  18.289684         34.7\n",
      "4          deferred_income  11.458477         66.7\n",
      "5                poi_ratio  10.019415         40.3\n",
      "6      long_term_incentive   9.922186         54.9\n",
      "7         restricted_stock   9.212811         24.3\n",
      "8           total_payments   8.772778         14.6\n",
      "9  shared_receipt_with_poi   8.589421         40.3\n",
      "\n",
      "##############################################################################################\n",
      "best_a_clf\n",
      "\n",
      "Pipeline(steps=[('scale_features', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('adaboost', Pipeline(steps=[('reduce_dim', PCA(copy=True, n_components=0.95, whiten=False)), ('adaboost', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=2,\n",
      "          n_estimators=5, random_state=None))]))])\n",
      "\tAccuracy: 0.89220\tPrecision: 0.67914\tRecall: 0.36300\tF1: 0.47312\tF2: 0.40026\n",
      "\tTotal predictions: 15000\tTrue positives:  726\tFalse positives:  343\tFalse negatives: 1274\tTrue negatives: 12657\n",
      "\n",
      "##############################################################################################\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import test_classifier, dump_classifier_and_data\n",
    "\n",
    "#additional imports\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import enron_tools\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "sep = '##############################################################################################'\n",
    "sep2 = '++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++'\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )\n",
    "\n",
    "### create list of functions for use as argument to add_features function\n",
    "add_feature_function_list = [enron_tools.add_poi_to_ratio,enron_tools.add_poi_from_ratio,enron_tools.add_poi_interaction_ratio]\n",
    "\n",
    "## add features to data_dict\n",
    "enron_tools.add_features(add_feature_function_list,data_dict)\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "\n",
    "data_label = 'poi'\n",
    "features_list = enron_tools.get_features(data_dict)\n",
    "\n",
    "\n",
    "## email address does not help with prediction and causes exeception, remove\n",
    "features_list.remove('email_address')\n",
    "\n",
    "\n",
    "##remove the data_label so that it can be re-added as the first feature element\n",
    "features_list.remove('poi')\n",
    "\n",
    "##reassemble feaures with the data label as the first element\n",
    "features_list = [data_label] + features_list\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "\n",
    "outliers = ['TOTAL','THE TRAVEL AGENCY IN THE PARK']\n",
    "\n",
    "enron_tools.remove_outliers(data_dict, outliers)\n",
    "\n",
    "\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "### Continue Feature Selection and dimensionality reduction via get_k_best\n",
    "\n",
    "## get k (k represents number of features) best features\n",
    "k = 10\n",
    "k_best_features = enron_tools.get_k_best(data_dict,features_list,k)\n",
    "\n",
    "print sep\n",
    "\n",
    "# assemble feature list\n",
    "my_features_list = [data_label] + list(k_best_features.feature.values)\n",
    "\n",
    "\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "### extract features and labels for gridsearch optimization\n",
    "\n",
    "# data extraction using k_best features list\n",
    "data = featureFormat(my_dataset, my_features_list, sort_keys = True)\n",
    "\n",
    "tru, trn = targetFeatureSplit(data)\n",
    "\n",
    "## scale extracted features\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "trn = scaler.fit_transform(trn)\n",
    "\n",
    "\n",
    "# Set up cross validator (will be used for tuning all classifiers)\n",
    "cv = cross_validation.StratifiedShuffleSplit(tru,\n",
    "                                            n_iter = 10,\n",
    "                                             random_state = 42)\n",
    "\n",
    "## Evaluate Final Adaboost Classifier\n",
    "\n",
    "# load tuned classifier pipeline\n",
    "\n",
    "\n",
    "best_a_pipe = pickle.load(open('best_clf_pipe.pkl', \"r\") )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print 'best_a_clf\\n'\n",
    "best_a_pipe\n",
    "test_classifier(best_a_pipe,my_dataset,my_features_list)\n",
    "print sep\n",
    "\n",
    "### Dump your classifier, dataset, and features_list so \n",
    "### anyone can run/check your results.\n",
    "\n",
    "dump_classifier_and_data(best_a_pipe, my_dataset, my_features_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
